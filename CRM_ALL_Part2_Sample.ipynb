{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from itertools import product as iterproduct\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pandas as pd \n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from itertools import product as iterproduct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = pickle.load( open( \"CRM_ALL_Dataset_x.p\", \"rb\" ) )\n",
    "y = pickle.load( open( \"CRM_ALL_Dataset_y.p\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1355, 3172)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def report(results, n_top=10):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_accuracy'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "          \n",
    "            print(\"Mean Test Accuracy Score: {0:.3f} \".format(\n",
    "                  results['mean_test_accuracy'][candidate]))\n",
    "\n",
    "            print(\"Mean Test Precision Score(Macro): {0:.3f} \".format(\n",
    "                  results['mean_test_precision_macro'][candidate]))\n",
    "            \n",
    "            print(\"Mean Test Recall Score(Macro): {0:.3f} )\".format(\n",
    "                  results['mean_test_recall_macro'][candidate]))\n",
    "            \n",
    "            print(\"Mean Test F1 Score(Macro): {0:.3f} \".format(\n",
    "                  results['mean_test_f1_macro'][candidate]))\n",
    "\n",
    "            print(\"Mean Test Precision Score(Weighted): {0:.3f} \".format(\n",
    "                  results['mean_test_precision_weighted'][candidate]))\n",
    "            \n",
    "            print(\"Mean Test Recall Score(Weighted): {0:.3f} \".format(\n",
    "                  results['mean_test_recall_weighted'][candidate]))\n",
    "            \n",
    "            print(\"Mean Test F1 Score(Weighted): {0:.3f} \".format(\n",
    "                  results['mean_test_f1_weighted'][candidate]))\n",
    "            \n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scoring = ['accuracy','f1_macro','precision_macro','recall_macro','f1_weighted','precision_weighted','recall_weighted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['accuracy',\n",
       " 'f1_macro',\n",
       " 'precision_macro',\n",
       " 'recall_macro',\n",
       " 'f1_weighted',\n",
       " 'precision_weighted',\n",
       " 'recall_weighted']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_grid={'hidden_layer_sizes': [(50, 50),\n",
    "  (50, 100),\n",
    "  (50, 150),\n",
    "  (50, 200),\n",
    "  (50, 250),\n",
    "  (50, 500),\n",
    "  (50, 750),\n",
    "  (50, 1000),\n",
    "  (50, 1250),\n",
    "  (50, 1500),\n",
    "  (50, 1750),\n",
    "  (50, 2000),\n",
    "  (50, 2250),\n",
    "  (50, 2500),\n",
    "  (50, 2750),\n",
    "  (50, 3000)],\n",
    " 'activation': ['logistic', 'tanh'],\n",
    " 'alpha': [0.0001, 0.0005, 0.001, 0.0015, 0.002]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hidden_layer_sizes': [(50, 50),\n",
       "  (50, 100),\n",
       "  (50, 150),\n",
       "  (50, 200),\n",
       "  (50, 250),\n",
       "  (50, 500),\n",
       "  (50, 750),\n",
       "  (50, 1000),\n",
       "  (50, 1250),\n",
       "  (50, 1500),\n",
       "  (50, 1750),\n",
       "  (50, 2000),\n",
       "  (50, 2250),\n",
       "  (50, 2500),\n",
       "  (50, 2750),\n",
       "  (50, 3000)],\n",
       " 'activation': ['logistic', 'tanh'],\n",
       " 'alpha': [0.0001, 0.0005, 0.001, 0.0015, 0.002]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = GridSearchCV(MLPClassifier(max_iter=500),\n",
    "                      param_grid,refit='accuracy',\n",
    "                      n_jobs=-1,\n",
    "                      scoring=scoring,\n",
    "                      cv=StratifiedKFold(n_splits=10,shuffle=True)\n",
    "                      ,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 160 candidates, totalling 1600 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 32 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 136 tasks      | elapsed: 154.8min\n",
      "[Parallel(n_jobs=-1)]: Done 386 tasks      | elapsed: 393.8min\n",
      "[Parallel(n_jobs=-1)]: Done 736 tasks      | elapsed: 759.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1186 tasks      | elapsed: 947.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1600 out of 1600 | elapsed: 1082.0min finished\n",
      "/home/wlsadmin/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "result.fit(x, y)\n",
    "pickle.dump( result, open( \"Result_CRM_ALL_Part_2.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with rank: 1\n",
      "Mean Test Accuracy Score: 0.852 \n",
      "Mean Test Precision Score(Macro): 0.754 \n",
      "Mean Test Recall Score(Macro): 0.662 )\n",
      "Mean Test F1 Score(Macro): 0.691 \n",
      "Mean Test Precision Score(Weighted): 0.848 \n",
      "Mean Test Recall Score(Weighted): 0.852 \n",
      "Mean Test F1 Score(Weighted): 0.844 \n",
      "Parameters: {'activation': 'logistic', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 2750)}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean Test Accuracy Score: 0.849 \n",
      "Mean Test Precision Score(Macro): 0.775 \n",
      "Mean Test Recall Score(Macro): 0.660 )\n",
      "Mean Test F1 Score(Macro): 0.692 \n",
      "Mean Test Precision Score(Weighted): 0.848 \n",
      "Mean Test Recall Score(Weighted): 0.849 \n",
      "Mean Test F1 Score(Weighted): 0.841 \n",
      "Parameters: {'activation': 'logistic', 'alpha': 0.0015, 'hidden_layer_sizes': (50, 3000)}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean Test Accuracy Score: 0.848 \n",
      "Mean Test Precision Score(Macro): 0.766 \n",
      "Mean Test Recall Score(Macro): 0.655 )\n",
      "Mean Test F1 Score(Macro): 0.688 \n",
      "Mean Test Precision Score(Weighted): 0.846 \n",
      "Mean Test Recall Score(Weighted): 0.848 \n",
      "Mean Test F1 Score(Weighted): 0.839 \n",
      "Parameters: {'activation': 'logistic', 'alpha': 0.002, 'hidden_layer_sizes': (50, 1250)}\n",
      "\n",
      "Model with rank: 4\n",
      "Mean Test Accuracy Score: 0.847 \n",
      "Mean Test Precision Score(Macro): 0.740 \n",
      "Mean Test Recall Score(Macro): 0.654 )\n",
      "Mean Test F1 Score(Macro): 0.683 \n",
      "Mean Test Precision Score(Weighted): 0.842 \n",
      "Mean Test Recall Score(Weighted): 0.847 \n",
      "Mean Test F1 Score(Weighted): 0.839 \n",
      "Parameters: {'activation': 'logistic', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 500)}\n",
      "\n",
      "Model with rank: 5\n",
      "Mean Test Accuracy Score: 0.846 \n",
      "Mean Test Precision Score(Macro): 0.747 \n",
      "Mean Test Recall Score(Macro): 0.649 )\n",
      "Mean Test F1 Score(Macro): 0.679 \n",
      "Mean Test Precision Score(Weighted): 0.842 \n",
      "Mean Test Recall Score(Weighted): 0.846 \n",
      "Mean Test F1 Score(Weighted): 0.838 \n",
      "Parameters: {'activation': 'logistic', 'alpha': 0.0005, 'hidden_layer_sizes': (50, 2000)}\n",
      "\n",
      "Model with rank: 5\n",
      "Mean Test Accuracy Score: 0.846 \n",
      "Mean Test Precision Score(Macro): 0.768 \n",
      "Mean Test Recall Score(Macro): 0.651 )\n",
      "Mean Test F1 Score(Macro): 0.686 \n",
      "Mean Test Precision Score(Weighted): 0.847 \n",
      "Mean Test Recall Score(Weighted): 0.846 \n",
      "Mean Test F1 Score(Weighted): 0.839 \n",
      "Parameters: {'activation': 'logistic', 'alpha': 0.0005, 'hidden_layer_sizes': (50, 3000)}\n",
      "\n",
      "Model with rank: 5\n",
      "Mean Test Accuracy Score: 0.846 \n",
      "Mean Test Precision Score(Macro): 0.759 \n",
      "Mean Test Recall Score(Macro): 0.641 )\n",
      "Mean Test F1 Score(Macro): 0.677 \n",
      "Mean Test Precision Score(Weighted): 0.843 \n",
      "Mean Test Recall Score(Weighted): 0.846 \n",
      "Mean Test F1 Score(Weighted): 0.837 \n",
      "Parameters: {'activation': 'logistic', 'alpha': 0.002, 'hidden_layer_sizes': (50, 2750)}\n",
      "\n",
      "Model with rank: 8\n",
      "Mean Test Accuracy Score: 0.846 \n",
      "Mean Test Precision Score(Macro): 0.766 \n",
      "Mean Test Recall Score(Macro): 0.659 )\n",
      "Mean Test F1 Score(Macro): 0.691 \n",
      "Mean Test Precision Score(Weighted): 0.845 \n",
      "Mean Test Recall Score(Weighted): 0.846 \n",
      "Mean Test F1 Score(Weighted): 0.838 \n",
      "Parameters: {'activation': 'logistic', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 250)}\n",
      "\n",
      "Model with rank: 8\n",
      "Mean Test Accuracy Score: 0.846 \n",
      "Mean Test Precision Score(Macro): 0.751 \n",
      "Mean Test Recall Score(Macro): 0.660 )\n",
      "Mean Test F1 Score(Macro): 0.685 \n",
      "Mean Test Precision Score(Weighted): 0.850 \n",
      "Mean Test Recall Score(Weighted): 0.846 \n",
      "Mean Test F1 Score(Weighted): 0.840 \n",
      "Parameters: {'activation': 'logistic', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 3000)}\n",
      "\n",
      "Model with rank: 8\n",
      "Mean Test Accuracy Score: 0.846 \n",
      "Mean Test Precision Score(Macro): 0.748 \n",
      "Mean Test Recall Score(Macro): 0.669 )\n",
      "Mean Test F1 Score(Macro): 0.691 \n",
      "Mean Test Precision Score(Weighted): 0.845 \n",
      "Mean Test Recall Score(Weighted): 0.846 \n",
      "Mean Test F1 Score(Weighted): 0.840 \n",
      "Parameters: {'activation': 'tanh', 'alpha': 0.0005, 'hidden_layer_sizes': (50, 1750)}\n",
      "\n",
      "Model with rank: 8\n",
      "Mean Test Accuracy Score: 0.846 \n",
      "Mean Test Precision Score(Macro): 0.744 \n",
      "Mean Test Recall Score(Macro): 0.658 )\n",
      "Mean Test F1 Score(Macro): 0.681 \n",
      "Mean Test Precision Score(Weighted): 0.845 \n",
      "Mean Test Recall Score(Weighted): 0.846 \n",
      "Mean Test F1 Score(Weighted): 0.838 \n",
      "Parameters: {'activation': 'tanh', 'alpha': 0.0015, 'hidden_layer_sizes': (50, 200)}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report(result.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
