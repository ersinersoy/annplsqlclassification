{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from itertools import product as iterproduct\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pandas as pd \n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from itertools import product as iterproduct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1061, 1563)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = pickle.load( open( \"CMS_ALL_Dataset_x.p\", \"rb\" ) )\n",
    "y = pickle.load( open( \"CMS_ALL_Dataset_y.p\", \"rb\" ) )\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def report(results, n_top=10):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_accuracy'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "          \n",
    "            print(\"Mean Test Accuracy Score: {0:.3f} \".format(\n",
    "                  results['mean_test_accuracy'][candidate]))\n",
    "\n",
    "            print(\"Mean Test Precision Score(Macro): {0:.3f} \".format(\n",
    "                  results['mean_test_precision_macro'][candidate]))\n",
    "            \n",
    "            print(\"Mean Test Recall Score(Macro): {0:.3f} )\".format(\n",
    "                  results['mean_test_recall_macro'][candidate]))\n",
    "            \n",
    "            print(\"Mean Test F1 Score(Macro): {0:.3f} \".format(\n",
    "                  results['mean_test_f1_macro'][candidate]))\n",
    "\n",
    "            print(\"Mean Test Precision Score(Weighted): {0:.3f} \".format(\n",
    "                  results['mean_test_precision_weighted'][candidate]))\n",
    "            \n",
    "            print(\"Mean Test Recall Score(Weighted): {0:.3f} \".format(\n",
    "                  results['mean_test_recall_weighted'][candidate]))\n",
    "            \n",
    "            print(\"Mean Test F1 Score(Weighted): {0:.3f} \".format(\n",
    "                  results['mean_test_f1_weighted'][candidate]))\n",
    "            \n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scoring = ['accuracy','f1_macro','precision_macro','recall_macro','f1_weighted','precision_weighted','recall_weighted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['accuracy',\n",
       " 'f1_macro',\n",
       " 'precision_macro',\n",
       " 'recall_macro',\n",
       " 'f1_weighted',\n",
       " 'precision_weighted',\n",
       " 'recall_weighted']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_grid={'hidden_layer_sizes': [(50, 50),\n",
    "  (50, 100),\n",
    "  (50, 150),\n",
    "  (50, 200),\n",
    "  (50, 250),\n",
    "  (50, 500),\n",
    "  (50, 750),\n",
    "  (50, 1000),\n",
    "  (50, 1250),\n",
    "  (50, 1500),\n",
    "  (50, 1750),\n",
    "  (50, 2000),\n",
    "  (50, 2250),\n",
    "  (50, 2500),\n",
    "  (50, 2750),\n",
    "  (50, 3000)],\n",
    " 'activation': ['logistic', 'tanh'],\n",
    " 'alpha': [0.0001, 0.0005, 0.001, 0.0015, 0.002]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': ['logistic', 'tanh'],\n",
       " 'alpha': [0.0001, 0.0005, 0.001, 0.0015, 0.002],\n",
       " 'hidden_layer_sizes': [(50, 50),\n",
       "  (50, 100),\n",
       "  (50, 150),\n",
       "  (50, 200),\n",
       "  (50, 250),\n",
       "  (50, 500),\n",
       "  (50, 750),\n",
       "  (50, 1000),\n",
       "  (50, 1250),\n",
       "  (50, 1500),\n",
       "  (50, 1750),\n",
       "  (50, 2000),\n",
       "  (50, 2250),\n",
       "  (50, 2500),\n",
       "  (50, 2750),\n",
       "  (50, 3000)]}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = GridSearchCV(MLPClassifier(max_iter=500),\n",
    "                      param_grid,refit='accuracy',\n",
    "                      n_jobs=-1,\n",
    "                      scoring=scoring,\n",
    "                      cv=StratifiedKFold(n_splits=10,shuffle=True)\n",
    "                      ,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 320 candidates, totalling 3200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed: 72.0min\n",
      "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed: 325.0min\n",
      "[Parallel(n_jobs=2)]: Done 446 tasks      | elapsed: 753.9min\n",
      "[Parallel(n_jobs=2)]: Done 796 tasks      | elapsed: 1496.1min\n",
      "[Parallel(n_jobs=2)]: Done 1246 tasks      | elapsed: 2373.8min\n",
      "[Parallel(n_jobs=2)]: Done 1796 tasks      | elapsed: 3288.6min\n",
      "[Parallel(n_jobs=2)]: Done 2446 tasks      | elapsed: 3715.8min\n",
      "[Parallel(n_jobs=2)]: Done 3196 tasks      | elapsed: 4323.4min\n",
      "[Parallel(n_jobs=2)]: Done 3200 out of 3200 | elapsed: 4327.0min finished\n"
     ]
    }
   ],
   "source": [
    "result.fit(x, y)\n",
    "pickle.dump( result, open( \"Result_CMS_ALL_Part_2.p\", \"wb\" ) )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
